{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "19CH30018_Vardhan_NLP_CS60075_A3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUo_mkiioAvN"
      },
      "source": [
        "# Assignment 3 on Natural Language Processing\n",
        "\n",
        "## Date : 23rd October, 2021\n",
        "\n",
        "### Instructor : Prof. Sudeshna Sarkar\n",
        "\n",
        "### Teaching Assistants : Alapan Kuila, Aniruddha Roy, Prithwish Jana, Udit Desai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwxSPrEspDmn"
      },
      "source": [
        "The central idea of this assignment is to experiment  Name Entity Recogniztion using pretrained language model BERT. Please split the NER data with train and validation, and evaluate the model on the validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoDPJlDJpmB8"
      },
      "source": [
        "Please submit with outputs. Submissions without predicted outputs will be penalized. **Please install necessary packages according to the task.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilwxcEJToM48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "449477bf-dc7d-43be-a2a0-ab0fd74bb35e"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "\n",
        "import os\n",
        "#print(os.listdir(\"../input\"))\n",
        "!pip install pytorch-pretrained-bert\n",
        "!pip install seqeval\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.9.0+cu111)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.62.3)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.19.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
            "Requirement already satisfied: botocore<1.23.0,>=1.22.12 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.22.12)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.5.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.23.0,>=1.22.12->boto3->pytorch-pretrained-bert) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.23.0,>=1.22.12->boto3->pytorch-pretrained-bert) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.23.0,>=1.22.12->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (1.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRriQnXBn-2z"
      },
      "source": [
        "Read the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "cAgLy2qp9TRu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ec552cb-7ab9-40f1-bc66-e4e969f85342"
      },
      "source": [
        "'''from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dataset = \"/content/drive/MyDrive/Acads/A3_dataset.csv\"\n",
        "dframe = pd.read_csv(dataset, encoding = \"ISO-8859-1\", error_bad_lines=False)'''\n",
        "dframe = pd.read_csv(\"A3_dataset.csv\", encoding = \"ISO-8859-1\", error_bad_lines=False)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "b'Skipping line 281837: expected 25 fields, saw 34\\n'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "cb9e29cd3d9de99b21ebfedb930c4d59e813664d",
        "trusted": true,
        "id": "lxWnzF3e9TRw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "65e8a013-041b-4b05-e201-d90fb44f2bed"
      },
      "source": [
        "dframe.head()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>lemma</th>\n",
              "      <th>next-lemma</th>\n",
              "      <th>next-next-lemma</th>\n",
              "      <th>next-next-pos</th>\n",
              "      <th>next-next-shape</th>\n",
              "      <th>next-next-word</th>\n",
              "      <th>next-pos</th>\n",
              "      <th>next-shape</th>\n",
              "      <th>next-word</th>\n",
              "      <th>pos</th>\n",
              "      <th>prev-iob</th>\n",
              "      <th>prev-lemma</th>\n",
              "      <th>prev-pos</th>\n",
              "      <th>prev-prev-iob</th>\n",
              "      <th>prev-prev-lemma</th>\n",
              "      <th>prev-prev-pos</th>\n",
              "      <th>prev-prev-shape</th>\n",
              "      <th>prev-prev-word</th>\n",
              "      <th>prev-shape</th>\n",
              "      <th>prev-word</th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>shape</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>thousand</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstr</td>\n",
              "      <td>NNS</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>IN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>of</td>\n",
              "      <td>NNS</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__start1__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__start2__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>wildcard</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>wildcard</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>1.0</td>\n",
              "      <td>capitalized</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstr</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "      <td>thousand</td>\n",
              "      <td>NNS</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__start1__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>wildcard</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>capitalized</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>1.0</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>demonstr</td>\n",
              "      <td>have</td>\n",
              "      <td>march</td>\n",
              "      <td>VBN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBP</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "      <td>thousand</td>\n",
              "      <td>NNS</td>\n",
              "      <td>capitalized</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>of</td>\n",
              "      <td>1.0</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>have</td>\n",
              "      <td>march</td>\n",
              "      <td>through</td>\n",
              "      <td>IN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>through</td>\n",
              "      <td>VBN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "      <td>demonstr</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>of</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>1.0</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>march</td>\n",
              "      <td>through</td>\n",
              "      <td>london</td>\n",
              "      <td>NNP</td>\n",
              "      <td>capitalized</td>\n",
              "      <td>London</td>\n",
              "      <td>IN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>through</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "      <td>demonstr</td>\n",
              "      <td>NNS</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>have</td>\n",
              "      <td>1.0</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0     lemma next-lemma  ...        shape           word tag\n",
              "0           0  thousand         of  ...  capitalized      Thousands   O\n",
              "1           1        of   demonstr  ...    lowercase             of   O\n",
              "2           2  demonstr       have  ...    lowercase  demonstrators   O\n",
              "3           3      have      march  ...    lowercase           have   O\n",
              "4           4     march    through  ...    lowercase        marched   O\n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "c598cf2c955b71ac3371bf6ebb19169b5734e5f5",
        "trusted": true,
        "id": "psG8otB69TRw"
      },
      "source": [
        "dataset=dframe.drop(['Unnamed: 0', 'lemma', 'next-lemma', 'next-next-lemma', 'next-next-pos',\n",
        "       'next-next-shape', 'next-next-word', 'next-pos', 'next-shape',\n",
        "       'next-word', 'prev-iob', 'prev-lemma', 'prev-pos',\n",
        "       'prev-prev-iob', 'prev-prev-lemma', 'prev-prev-pos', 'prev-prev-shape',\n",
        "       'prev-prev-word', 'prev-shape', 'prev-word','shape'],axis=1)\n",
        "\n",
        "#dataset = dframe.dropdframe.drop([])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "c31cfa31598d78e73db241816ee8f7d98e7b320f",
        "trusted": true,
        "id": "5tFVIgyy9TRx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4f57ff0a-7fb3-453a-bb4a-7f41fb29602d"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pos</th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NNS</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>IN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NNS</td>\n",
              "      <td>1.0</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>VBP</td>\n",
              "      <td>1.0</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>VBN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   pos  sentence_idx           word tag\n",
              "0  NNS           1.0      Thousands   O\n",
              "1   IN           1.0             of   O\n",
              "2  NNS           1.0  demonstrators   O\n",
              "3  VBP           1.0           have   O\n",
              "4  VBN           1.0        marched   O"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4gvBBQvqMra"
      },
      "source": [
        "Preprocess the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "27bac58d6d0a7c67a2e7ca71329ec89b86006cdc",
        "trusted": true,
        "id": "zq9n23HS9TRx"
      },
      "source": [
        "class SentenceGetter(object):\n",
        "    \n",
        "    def __init__(self, dataset):\n",
        "        self.n_sent = 1\n",
        "        self.dataset = dataset\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w,p, t) for w,p, t in zip(s[\"word\"].values.tolist(),\n",
        "                                                       s['pos'].values.tolist(),\n",
        "                                                        s[\"tag\"].values.tolist())]\n",
        "        self.grouped = self.dataset.groupby(\"sentence_idx\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ce9bb377d28f1062740ed52955e4473b9a91a915",
        "trusted": true,
        "id": "cjo3lxMD9TRy"
      },
      "source": [
        "getter = SentenceGetter(dataset)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "9aac920912c2846b8f01e7a9fac7a1dd75f470e5",
        "trusted": true,
        "id": "xVlKwn649TRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "37998088-c1e0-4304-cec6-9a0fc9ac433c"
      },
      "source": [
        "sentences = [\" \".join([s[0] for s in sent]) for sent in getter.sentences]\n",
        "sentences[0]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country . Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .'"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ef108c6958dccc1855966ece23d582a0a427ffce",
        "trusted": true,
        "id": "2rZRrXAA9TR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6a7d42b-1993-4ef6-a40e-2d9da1c24f39"
      },
      "source": [
        "labels = [[s[2] for s in sent] for sent in getter.sentences]\n",
        "print(labels[0])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "7e274ec75490323bdbc5f0227d62fd17d3de90da",
        "trusted": true,
        "id": "RpGTxb6o9TR2"
      },
      "source": [
        "tags_vals = list(set(dataset[\"tag\"].values))\n",
        "tag2idx = {t: i for i, t in enumerate(tags_vals)}"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MOg7AYgqW7Z"
      },
      "source": [
        "Import model pacakages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "1cdd149a0e14d9e9291bdf993f01c6fedb02d6ac",
        "trusted": true,
        "id": "CNIUugH29TR3"
      },
      "source": [
        "import torch\n",
        "import random\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertForTokenClassification, BertAdam\n",
        "from tqdm import tqdm, trange"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMkMbt9dq7Qx"
      },
      "source": [
        "Set up seed value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9roxUsuq-s6"
      },
      "source": [
        "# setup random seed\n",
        "seed =42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "9bf2b8a2864802dae72ff7313e833a2c4d26fe73",
        "trusted": true,
        "id": "jUd3mFKc9TR4"
      },
      "source": [
        "MAX_LEN = 40\n",
        "bs =64"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "f57a27970f56c488884c464ab87ac8228e4a0e72",
        "trusted": true,
        "id": "iS88Oaz99TR4"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "01c72c953cf95d447e1376dfc5b7d349868bb0a6",
        "trusted": true,
        "id": "em4XP5la9TR5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1c3058b4-4893-4b32-bf7a-f3043198a6e5"
      },
      "source": [
        "torch.cuda.get_device_name(0) "
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla K80'"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrW_k60XrUQ1"
      },
      "source": [
        "Features generation  for pre-trained languge BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "115b9ebaeeb38126bd30bb825e00fdf2220c20df",
        "trusted": true,
        "id": "Q2lil3kW9TR5"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "e1a671a466e656bdf14158365d0fc66273abf6ae",
        "trusted": true,
        "id": "4fPn_NPU9TR5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07d2078f-6267-4d2d-af7d-eaae41afbfad"
      },
      "source": [
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "print(tokenized_texts[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.', 'thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "f77f0f8f9c779c15b49790cf9c42becef3f39cba",
        "trusted": true,
        "id": "6cS5w4PS9TR5"
      },
      "source": [
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "7f28fe1c656c371e47b23a6d905527da9895d3ee",
        "trusted": true,
        "id": "C5oXcoOb9TR6"
      },
      "source": [
        "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"O\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "42250d53714a7a30d23778ff0692ee7aed5018b3",
        "trusted": true,
        "id": "sc8MJKdv9TR7"
      },
      "source": [
        "attention_masks = [[float(i>0) for i in ii] for ii in input_ids]"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "7983cec40eaf72173ff1de156a2e5bc5f746f6b6",
        "trusted": true,
        "id": "mgLwrHgK9TR7"
      },
      "source": [
        "tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "809efdd5002265fad91a3c2e5b019d14e48987c2",
        "trusted": true,
        "id": "JfPfWHpb9TR7"
      },
      "source": [
        "tr_inputs = torch.tensor(tr_inputs)\n",
        "val_inputs = torch.tensor(val_inputs)\n",
        "tr_tags = torch.tensor(tr_tags)\n",
        "val_tags = torch.tensor(val_tags)\n",
        "tr_masks = torch.tensor(tr_masks)\n",
        "val_masks = torch.tensor(val_masks)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "a7d0ab1dd92524ede3f8cfd868d47fa854e3b7f7",
        "trusted": true,
        "id": "qb46kFc09TR7"
      },
      "source": [
        "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
        "\n",
        "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "907a1068525b1c1fd64cd5641af29fdcff498c89",
        "trusted": true,
        "id": "zc2fkUYJ9TR7"
      },
      "source": [
        "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(tag2idx))"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "553fc0c1015878731b5c2ab4185026bd44101695",
        "trusted": true,
        "id": "MgvCcJ1k9TR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dbde5ff-551b-44cf-ea38-1eb8b4846b4c"
      },
      "source": [
        "model.cuda()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=18, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "c32ef5fb14eee369b8b945f48316b8f973a812d6",
        "trusted": true,
        "id": "Ag1OLUtg9TR8"
      },
      "source": [
        "param_optimizer = list(model.classifier.named_parameters()) \n",
        "optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "3486fe719942f089d4041d6db192154cd4ba6052",
        "trusted": true,
        "id": "4fSU0CFV9TR9"
      },
      "source": [
        "from seqeval.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def model_validation_accuracy(model):\n",
        "  model.eval()\n",
        "  predictions,true_labels,accuracy_batch_wise= [], [] , []\n",
        "\n",
        "  for batch in valid_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    logits = outputs.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    #Using the above created flat accuracy function\n",
        "    accuracy_batch_wise.append(flat_accuracy(logits,label_ids))\n",
        "    predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "    true_labels.extend(label_ids)\n",
        "  return predictions,true_labels,accuracy_score(predictions, true_labels)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "f76abc8a8fcc868095f325515f2c5ecb43c02859",
        "trusted": true,
        "id": "2AJr3d8c9TR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5e3f6d5-6018-43e4-9f13-a6c907f150ac"
      },
      "source": [
        "epochs = 5\n",
        "max_grad_norm = 1.0\n",
        "validation_accuracy,epoch_total_loss,loss_per_epoch = [] , [], []\n",
        "\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "    # TRAIN loop\n",
        "    model.train()\n",
        "    train_total_loss = 0\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        # forward pass\n",
        "        model.zero_grad()\n",
        "        get_model = model(b_input_ids, token_type_ids=None,\n",
        "                        attention_mask=b_input_mask, labels=b_labels)\n",
        "        #get the loss\n",
        "        loss = get_model\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        # track train loss\n",
        "        train_total_loss += loss.item()\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        \n",
        "        ## update parameters\n",
        "        optimizer.step()\n",
        "    __,___,validation_acc = model_validation_accuracy(model)\n",
        "    # print train loss per epoch\n",
        "    avg_train_loss = train_total_loss / len(train_dataloader)\n",
        "    print(\"\\nTotal Loss: {}\".format(train_total_loss))\n",
        "    print(\"Average train loss: {}\".format(avg_train_loss))\n",
        "    validation_accuracy.append(validation_acc)\n",
        "    epoch_total_loss.append(train_total_loss)\n",
        "    loss_per_epoch.append(avg_train_loss)\n",
        "    print()\n",
        "    #save your model after the final epoch\n",
        "    #Saving after every epoch (incase of any issues)\n",
        "    '''path = F\"/content/NLP_Assignment3_Model_Epochs.pt\" \n",
        "    torch.save(model.state_dict(), path)'''"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:  20%|██        | 1/5 [07:42<30:51, 462.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total Loss: 892.4201981425285\n",
            "Average train loss: 1.8028690871566233\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  40%|████      | 2/5 [15:26<23:09, 463.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total Loss: 419.5758949518204\n",
            "Average train loss: 0.8476280706097381\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  60%|██████    | 3/5 [23:11<15:28, 464.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total Loss: 345.06359255313873\n",
            "Average train loss: 0.6970981667740176\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  80%|████████  | 4/5 [31:03<07:47, 467.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total Loss: 320.8356241583824\n",
            "Average train loss: 0.6481527760775402\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 5/5 [38:55<00:00, 467.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total Loss: 309.46551182866096\n",
            "Average train loss: 0.6251828521791131\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm1Ni2a_VZrT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ef2cff5-6fe2-4d98-82d5-4582b801f99b"
      },
      "source": [
        "predictions, true_labels, final_validation_accuracy = model_validation_accuracy(model)\n",
        "n_epoch = 5\n",
        "print(\"- \"*10,\"Summary of the training epochs\",\" -\"*10)\n",
        "print()\n",
        "for epoch in range(n_epoch):\n",
        "  print(\"\\033[4mFor Epoch\",epoch,\":\\033[0m\")\n",
        "  print(\"Validation Accuracy:{}\".format(validation_accuracy[epoch]))\n",
        "  print(\"Total Loss: {}\".format(epoch_total_loss[epoch]))\n",
        "  print(\"Average train loss: {}\".format(loss_per_epoch[epoch]))\n",
        "  print()\n",
        "print(\"\\033[1mFinal Validation Accuracy of the Model: {}\\033[0m\".format(final_validation_accuracy))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- - - - - - - - - -  Summary of the training epochs  - - - - - - - - - -\n",
            "\n",
            "\u001b[4mFor Epoch 0 :\u001b[0m\n",
            "Validation Accuracy:0.8946631608868676\n",
            "Total Loss: 892.4201981425285\n",
            "Average train loss: 1.8028690871566233\n",
            "\n",
            "\u001b[4mFor Epoch 1 :\u001b[0m\n",
            "Validation Accuracy:0.8946702671972712\n",
            "Total Loss: 419.5758949518204\n",
            "Average train loss: 0.8476280706097381\n",
            "\n",
            "\u001b[4mFor Epoch 2 :\u001b[0m\n",
            "Validation Accuracy:0.8945423536100057\n",
            "Total Loss: 345.06359255313873\n",
            "Average train loss: 0.6970981667740176\n",
            "\n",
            "\u001b[4mFor Epoch 3 :\u001b[0m\n",
            "Validation Accuracy:0.8941586128482092\n",
            "Total Loss: 320.8356241583824\n",
            "Average train loss: 0.6481527760775402\n",
            "\n",
            "\u001b[4mFor Epoch 4 :\u001b[0m\n",
            "Validation Accuracy:0.8938175099488346\n",
            "Total Loss: 309.46551182866096\n",
            "Average train loss: 0.6251828521791131\n",
            "\n",
            "\u001b[1mFinal Validation Accuracy of the Model: 0.8938175099488346\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JZo9aAA67ti",
        "outputId": "97b9355f-d9d0-4a80-864f-269f57109dec"
      },
      "source": [
        "tagged_values = list(set(dataset[\"tag\"].values))\n",
        "tagged_values.append(\"PAD\")\n",
        "tag_idx = {t: i for i, t in enumerate(tagged_values)}\n",
        "\n",
        "predicted_tags = [tagged_values[p_i] for p, l in zip(predictions, true_labels)\n",
        "                              for p_i, l_i in zip(p, l) if tagged_values[l_i] != \"PAD\"]\n",
        "valid_tags = [tagged_values[l_i] for l in true_labels\n",
        "                              for l_i in l if tagged_values[l_i] != \"PAD\"]\n",
        "df_actual_pred=pd.DataFrame({\"Predicted Tags\":predicted_tags,\"Actual Tags\":valid_tags})\n",
        "print(df_actual_pred)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Predicted Tags Actual Tags\n",
            "0                   O           O\n",
            "1                   O           O\n",
            "2                   O           O\n",
            "3                   O           O\n",
            "4                   O           O\n",
            "...               ...         ...\n",
            "140715              O           O\n",
            "140716              O           O\n",
            "140717              O           O\n",
            "140718              O           O\n",
            "140719              O           O\n",
            "\n",
            "[140720 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "5c2f84d74b0913606ce9ea58ff5f36e605ad1110",
        "trusted": true,
        "id": "DzFsMeOT9TR-"
      },
      "source": [
        "#Save the  model and result\n",
        "df_actual_pred.to_csv('/content/19CH30018_NLP_Assignment3_Output.csv',index=False)\n",
        "path = F\"/content/19CH30018_NLP_Assignment3_Final_Model_Epochs.pt\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 81,
      "outputs": []
    }
  ]
}